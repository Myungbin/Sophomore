---
title: "텍스트마이닝 수능단어"
author: "데이터테크전공 20173204 곽명빈"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#install.packages("twitteR")
#install.packages("ROAuth")
library(twitteR)
library(ROAuth)
library("base64enc")
library(tm)
library(qdapRegex)
library(KoNLP)
library(dplyr)
library(wordcloud2)
library(wordcloud)
library(stringr)
library(htmlwidgets)
library(htmltools)
library(jsonlite)
library(yaml)
library(base64enc)
library(devtools)
devtools::install_github("lchiffon/wordcloud2")
library(qgraph)
library(ggplot2)
```

```{r}
consumer_key <- ''
consumer_secret <- ''
access_token <- ''
access_secret <- ''

requestURL <-"https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"

setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
twitCred <- OAuthFactory$new(consumerKey=consumer_key, consumerSecret=consumer_secret,requestURL=requestURL, accessURL=accessURL,authURL=authURL)

download.file(url="http://curl.haxx.se/ca/cacert.pem",destfile="cacert.pem")
```

## 트위터의 "수능" 데이터
```{r}
keyword <-enc2utf8("수능")
test <- searchTwitter(keyword, n = 800, lang = "ko")
head(test, 30)
df <- twListToDF(test)
```


## 데이터전처리
```{r}
word <- df$text     # 텍스트파일만
word <- rm_tag(word) 
word <- rm_url(word)
word <- gsub("*.:","", word)   
word <- gsub('[~!@#$%&*()_+=?<>]','',word)
word <- gsub("RT","", word)   
word <- gsub("/n","", word)   
word <- gsub("[A-Z]","", word)
word <- gsub("[a-z]","", word)
word <- gsub("[ㄱ-ㅎ]","", word)
word <- gsub('(ㅜ|ㅠ)','',word)
word <- gsub("\\d","", word)
word <- gsub("●","", word)
word <- gsub("[^\uAC00-\uD7A3xfe a-zA-Zㄱ-ㅎㅏ-ㅣ가-힣\\s]", "", word)

```

# 단어빈도

```{r}
nouns <- sapply(word, extractNoun, USE.NAMES = F)

nouns_unlist <- unlist(nouns)

nouns_unlist <- Filter(function(x){nchar(x)>=2}, nouns_unlist)
nouns_unlist <- gsub("수능에한국사가필수가된이", "한국사", nouns_unlist)


head(nouns_unlist, 30) 

extractNoun(nouns_unlist)

wordcount <- table(nouns_unlist)

wordcount_top <-head(sort(wordcount, decreasing = T),100)

wordcount_top      # 많이나온 단어

wordcloud2(wordcount_top, size=1.0)






letterCloud(data=wordcount_top,word='R',wordSize=0.5)

```

```{r}
df_word <- as.data.frame(wordcount_top, stringsAsFactors = T)
View(df_word)

df_word <- rename(df_word,
                  word = nouns_unlist,
                  freq = Freq)

top20 <- df_word %>%
  arrange(desc(freq)) %>%
  head(20)

order <- arrange(top20, freq)$word

ggplot(data = top20, aes(x = word, y = freq)) + 
  ylim(0, 800) + 
  geom_col() +
  coord_flip() + 
  scale_x_discrete(limit = order) + 
  geom_text(aes(label = freq), hjust = -0.3)

```

```{r}
tt <- paste(unlist(SimplePos22(nouns_unlist)))
allnoun <- str_match_all(tt, "[가-힣]+/[N][C]|[가-힣]+/[N][Q]+") %>% unlist()
N <- str_replace_all(allnoun, "/[N][C]", "") %>%
str_replace_all("/[N][Q]", "") %>% unlist() 
CorpusNC <- Corpus(VectorSource(N))
myDtm <- TermDocumentMatrix(CorpusNC, control = list(wordLengths = c(4, 10),
removePunctuation = T,
removeNumbers = T,
weighting = weightBin))

Encoding(myDtm$dimnames$Terms) = "UTF-8"
# 확인
findFreqTerms(myDtm, lowfreq = 10)

myDtmM <- as.matrix(myDtm) # 행렬로 변환
myrowDtmM <- rowSums(myDtmM)
myDtmM.order <- myrowDtmM[order(myrowDtmM, decreasing = T)]
freq.wordsNC <- myDtmM.order[1:20] ##sample(myDtmM.order[myDtmM.order > 5], 20,replace=F)인걸이거로 바꿈
freq.wordsNC <- as.matrix(freq.wordsNC)
freq.wordsNC

co.matrix <- freq.wordsNC %*% t(freq.wordsNC)
# qgraph
qgraph(co.matrix,
labels = rownames(co.matrix),
diag = F,
layout = 'spring',
vsize = log(diag(co.matrix)))

```
